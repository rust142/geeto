name: Auto-add AI Review Label (Ensure + Apply)

# This single workflow ensures the label exists and adds it to new issues, and then
# runs the AI assessment immediately (so a separate 'issues.labeled' trigger is not required).
# Also supports manual testing via workflow_dispatch with an `issue_number` input.
on:
  issues:
    types: [opened]
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number to process (optional; for manual testing)'
        required: false
        type: number
  push:
    branches: [ main, develop ]

permissions:
  issues: write
  models: read
  contents: read

jobs:
  add-label:
    runs-on: ubuntu-latest

    steps:
      - name: Ensure label exists
        uses: actions/github-script@v7
        with:
          script: |
            const labelName = 'request ai review';
            const color = '6f42c1';
            const description = 'Trigger AI Issue Assessment action';

            // Create label if it doesn't exist
            try {
              await github.rest.issues.getLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                name: labelName,
              });
            } catch (err) {
              await github.rest.issues.createLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                name: labelName,
                color,
                description,
              });
            }

      - name: Prepare issue context
        id: prepare_issue
        uses: actions/github-script@v7
        with:
          script: |
            // Robustly determine issue number from workflow input or event payload
            const ctx = (typeof context !== 'undefined' ? context : (github && github.context ? github.context : {}));
            const payload = (ctx && ctx.payload) ? ctx.payload : {};
            const inputIssue = payload.inputs ? payload.inputs.issue_number : undefined;
            const issueNumber = inputIssue ? Number(inputIssue) : (payload.issue ? payload.issue.number : undefined);

            // If no issue number or octokit not available, skip gracefully
            if (!issueNumber || typeof github === 'undefined') {
              core.info('No issue number provided or octokit not available; skipping further steps.');
              return { issue_number: '', issue_body: '' };
            }

            const { data: issue } = await github.rest.issues.get({
              owner: (ctx && ctx.repo && ctx.repo.owner) ? ctx.repo.owner : github.context.repo.owner,
              repo: (ctx && ctx.repo && ctx.repo.repo) ? ctx.repo.repo : github.context.repo.repo,
              issue_number: issueNumber,
            });

            core.info(`Prepared issue #${issueNumber}`);
            core.setOutput('issue_number', String(issueNumber));
            core.setOutput('issue_body', issue.body || '');
            return { issue_number: String(issueNumber), issue_body: issue.body || '' };

      - name: Add label to issue (if available)
        if: ${{ steps.prepare_issue.outputs.issue_number != '' }}
        uses: actions/github-script@v7
        with:
          script: |
            const labelName = 'request ai review';
            const issueNumber = Number('${{ steps.prepare_issue.outputs.issue_number }}');
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              labels: [labelName],
            });

      - name: Run AI assessment (for the target issue)
        if: ${{ steps.prepare_issue.outputs.issue_number != '' }}
        id: ai-assessment
        uses: github/ai-assessment-comment-labeler@v1.0.1
        with:
          token: "${{ secrets.GITHUB_TOKEN }}"
          ai_review_label: 'request ai review'
          issue_number: "${{ steps.prepare_issue.outputs.issue_number }}"
          issue_body: "${{ steps.prepare_issue.outputs.issue_body }}"
          repo_name: "${{ github.event.repository.name }}"
          prompts_directory: './prompts'
          labels_to_prompts_mapping: 'bug,bug-review.prompt.yml'

      - name: Debug - show ai_assessments output
        if: ${{ steps.prepare_issue.outputs.issue_number != '' }}
        run: |
          echo 'AI assessments output:'
          echo "${{ steps.ai-assessment.outputs.ai_assessments }}"
          echo '----'
          echo 'Check issue comments and labels in the web UI for results.'
